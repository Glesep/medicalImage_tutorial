{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d131228f",
   "metadata": {},
   "source": [
    "## Preprocessing for 2.5D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5a35c1",
   "metadata": {},
   "source": [
    ".mha -> .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd5d190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586a7633",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# 원본 파일 저장 경로\n",
    "MHA_PATH_ORIGIN = os.getenv(\"MHA_PATH_ORIGIN\")\n",
    "MHA_PATH_AB = os.getenv(\"MHA_PATH_AB\")\n",
    "MHA_PATH_TH = os.getenv(\"MHA_PATH_TH\")\n",
    "MHA_PATH_HN = os.getenv(\"MHA_PATH_HN\")\n",
    "\n",
    "# .npy 파일 저장 경로\n",
    "npy_dir = os.path.join(MHA_PATH_ORIGIN, 'Task2_npy', 'AB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bb9266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_files_pathlib(root_dir, type):\n",
    "    root_path = Path(root_dir)\n",
    "    # rglob 결과에서 is_file()인 항목만 필터링\n",
    "    return [p for p in root_path.rglob('*') if p.is_file() \n",
    "            and (p.name == f'{type}.mha')]\n",
    "\n",
    "def normalize_and_resize_to_float(slice_img, target_size):\n",
    "    \"\"\"\n",
    "    단일 2D 슬라이스를 [-1.0, 1.0] float로 정규화 후 크기 조정\n",
    "    \"\"\"\n",
    "    MIN_HU = -1000\n",
    "    MAX_HU = 2000\n",
    "    \n",
    "    # HU Windowing (Clamping)\n",
    "    slice_img = np.clip(slice_img, MIN_HU, MAX_HU)\n",
    "\n",
    "    # min-max 정규화 ([-1.0, 1.0])\n",
    "    # [MIN_HU, MAX_HU] 범위를 [-1.0, 1.0]로 스케일링\n",
    "    normalized_slice = ((slice_img - MIN_HU) / (MAX_HU - MIN_HU))* 2.0 - 1.0\n",
    "    \n",
    "    \n",
    "    # 3. 리사이즈 (float 상태로 리사이즈)\n",
    "    resized_slice = cv2.resize(normalized_slice.astype(np.float32), \n",
    "                               target_size, \n",
    "                               interpolation=cv2.INTER_AREA)        # 축소 시 가장 권장되는 보간법\n",
    "    \n",
    "    return resized_slice # [H, W] 크기의 float32 배열 반환\n",
    "\n",
    "def process_volume_to_2_5d(volume_path, output_dir, patient_name):\n",
    "    \"\"\"\n",
    "    MHA 볼륨 1개를 2.5D (3-channel) .npy 파일들로 변환하여 저장\n",
    "    \"\"\"\n",
    "    TARGET_SIZE = (256, 256)\n",
    "    try:\n",
    "        # 1. MHA 파일 로드\n",
    "        sitk_img = sitk.ReadImage(volume_path)\n",
    "        \n",
    "        # 2. NumPy 배열로 변환 [Depth, Height, Width] (z, y, x)\n",
    "        volume_data = sitk.GetArrayFromImage(sitk_img)\n",
    "        \n",
    "        num_slices = volume_data.shape[0]\n",
    "\n",
    "        if num_slices < 3:\n",
    "            print(f\"Skipping {patient_name}: Not enough slices (< 3)\")\n",
    "            return\n",
    "\n",
    "        # 3. 2.5D (3-slice) 처리\n",
    "        for z in range(1, num_slices - 1):\n",
    "            \n",
    "            slice_prev = normalize_and_resize_to_float(volume_data[z - 1, :, :], TARGET_SIZE)\n",
    "            slice_curr = normalize_and_resize_to_float(volume_data[z,     :, :], TARGET_SIZE)\n",
    "            slice_next = normalize_and_resize_to_float(volume_data[z + 1, :, :], TARGET_SIZE)\n",
    "            \n",
    "            # 4. 채널(channel) 축으로 스택\n",
    "            # 결과물: [Height, Width, 3] 모양의 'float32' 텐서\n",
    "            stacked_image = np.stack([slice_prev, slice_curr, slice_next], axis=-1)\n",
    "            \n",
    "            # 5. 파일 저장 (Numpy .npy)\n",
    "            output_filename = f\"{patient_name}_slice_{z:04d}.npy\"\n",
    "            output_path = os.path.join(output_dir, output_filename)\n",
    "            \n",
    "            np.save(output_path, stacked_image)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {volume_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60b715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pList_AB_cbct = get_all_files_pathlib(MHA_PATH_AB, 'cbct')\n",
    "pList_AB_ct = get_all_files_pathlib(MHA_PATH_AB, 'ct')\n",
    "pList_TN_cbct = get_all_files_pathlib(MHA_PATH_TH, 'cbct')\n",
    "pList_TN_ct = get_all_files_pathlib(MHA_PATH_TH, 'ct')\n",
    "pList_HN_cbct = get_all_files_pathlib(MHA_PATH_HN, 'cbct')\n",
    "pList_HN_ct = get_all_files_pathlib(MHA_PATH_HN, 'ct')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61003493",
   "metadata": {},
   "source": [
    "abnomial image만 고려"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464cbbf8",
   "metadata": {},
   "source": [
    "train / test 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651d0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(pList_AB_cbct)\n",
    "random.shuffle(pList_AB_ct)\n",
    "\n",
    "TEST_SPLIT_RATIO = 0.3\n",
    "\n",
    "cbct_split_idx = int(len(pList_AB_cbct) * TEST_SPLIT_RATIO)\n",
    "ct_split_idx = int(len(pList_AB_ct) * TEST_SPLIT_RATIO)\n",
    "\n",
    "test_pList_AB_cbct = pList_AB_cbct[:cbct_split_idx]\n",
    "train_pList_AB_cbct = pList_AB_cbct[cbct_split_idx:]\n",
    "\n",
    "test_pList_AB_ct = pList_AB_ct[:ct_split_idx]\n",
    "train_pList_AB_ct = pList_AB_ct[ct_split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae94bc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CycleGAN 폴더 구조 생성\n",
    "dir_map = {\n",
    "    os.path.join(npy_dir, \"trainA\"): train_pList_AB_cbct,\n",
    "    os.path.join(npy_dir, \"trainB\"): train_pList_AB_ct,\n",
    "    os.path.join(npy_dir, \"testA\"): test_pList_AB_cbct,\n",
    "    os.path.join(npy_dir, \"testB\"): test_pList_AB_ct,\n",
    "}\n",
    "\n",
    "\n",
    "for output_dir, file_list in dir_map.items():\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"\\nProcessing files for: {os.path.basename(output_dir)}\")\n",
    "    print(f\"Found {len(file_list)} volumes.\")\n",
    "    \n",
    "    for i, f_path in enumerate(tqdm(file_list, desc=f\"Creating {os.path.basename(output_dir)}\")):\n",
    "        patient_name = f'patient_{i}'\n",
    "        \n",
    "        domain_prefix = \"cbct\" if \"A\" in output_dir else \"ct\"\n",
    "        patient_name = f\"{domain_prefix}_{patient_name}\"\n",
    "        process_volume_to_2_5d(f_path, output_dir, patient_name)\n",
    "print(\"\\n---------------------------------\")\n",
    "print(f\"Dataset creation complete\")\n",
    "print(\"All files are saved as .npy (float32, -1.0 to 1.0)\")\n",
    "print(\"---------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
